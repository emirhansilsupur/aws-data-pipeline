{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EV Charging Prediction using Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker import image_uris\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder,RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up S3 client and bucket information\n",
    "s3 = boto3.client(\"s3\")\n",
    "bucket_name=\"ev-charging-processed\"\n",
    "input_data_path = \"s3://ev-charging-processed/data/part-00000-e0b3237a-add5-471c-ba5e-111b16d710db-c000.snappy.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(input_data_path, training_data_folder = \"training_data\"):\n",
    "    # Read the input data\n",
    "    df = pd.read_parquet(input_data_path)\n",
    "\n",
    "    # Define feature groups\n",
    "    numerical_features = [\n",
    "        \"distance_driven_(since_last_charge)_(km)\", \"temperature_(Â°c)\",\n",
    "        \"vehicle_age_(years)\", \"charging_start_hour\", \"charging_start_day\",\n",
    "        \"charging_end_hour\", \"charging_end_day\", \"charging_rate_x_battery_capacity\",\n",
    "        \"temperature_x_charging_duration\", \"effective_battery_capacity_(kwh)\",\n",
    "        \"battery_percentage_charged\", \"charging_duration_(hours)\", \"charging_rate_(kw)\"\n",
    "    ]\n",
    "    ohe_columns = [\"vehicle_model\", \"charging_station_location\", \"time_of_day\", \"user_type\"]\n",
    "    ordinal_columns = [\"charger_type\"]\n",
    "\n",
    "    target_column = [\"energy_consumed_(kwh)\"]\n",
    "\n",
    "    # Prepare the dataset\n",
    "    df_ = df[target_column + numerical_features + ohe_columns + ordinal_columns]\n",
    "\n",
    "    # Define preprocessing steps\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", RobustScaler())\n",
    "    ])\n",
    "\n",
    "    ordinal_transformer = Pipeline(steps=[\n",
    "        (\"ordinal\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1,\n",
    "                                   categories=[[\"Level 1\", \"Level 2\", \"DC Fast Charger\"]]))\n",
    "    ])\n",
    "\n",
    "    ohe_transformer = Pipeline(steps=[\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        (\"numeric\", numeric_transformer, numerical_features),\n",
    "        (\"ordinal\", ordinal_transformer, ordinal_columns),\n",
    "        (\"ohe\", ohe_transformer, ohe_columns)\n",
    "    ])\n",
    "\n",
    "    # Split the data\n",
    "    X = df_.drop(target_column, axis=1)\n",
    "    y = df_[target_column]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fit and transform the training data\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_val)\n",
    "\n",
    "    # Convert to DataFrame and add target column\n",
    "    feature_names = (numerical_features +\n",
    "                     ordinal_columns +\n",
    "                     preprocessor.named_transformers_[\"ohe\"].get_feature_names_out(ohe_columns).tolist())\n",
    "    \n",
    "    train_df = pd.DataFrame(X_train_processed, columns=feature_names)\n",
    "    train_df[\"energy_consumed_(kwh)\"] = y_train.values\n",
    "\n",
    "    test_df = pd.DataFrame(X_test_processed, columns=feature_names)\n",
    "    test_df[\"energy_consumed_(kwh)\"] = y_val.values\n",
    "\n",
    "    train_df = train_df[[\"energy_consumed_(kwh)\"] + [col for col in train_df.columns if col != \"energy_consumed_(kwh)\"]]\n",
    "    test_df = test_df[[\"energy_consumed_(kwh)\"] + [col for col in test_df.columns if col != \"energy_consumed_(kwh)\"]]\n",
    "\n",
    "    training_data_object = \"training_data.csv\"\n",
    "    validation_data_object = \"validation_data.csv\"\n",
    "\n",
    "    # Save processed data\n",
    "    train_df.to_csv(training_data_object, index=False, header=False)\n",
    "    test_df.to_csv(validation_data_object, index=False, header=False)\n",
    "\n",
    "    # upload to S3\n",
    "    sagemaker.Session().upload_data(path=training_data_object, bucket=bucket_name, key_prefix=training_data_folder)\n",
    "    sagemaker.Session().upload_data(path=validation_data_object, bucket=bucket_name, key_prefix=training_data_folder)\n",
    "\n",
    "    print(f\"Training data uploaded to s3://{bucket_name}/{training_data_folder}/{training_data_object}\")\n",
    "    print(f\"Validation data uploaded to s3://{bucket_name}/{training_data_folder}/{validation_data_object}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data uploaded to s3://ev-charging-processed/training_data/training_data.csv\n",
      "Validation data uploaded to s3://ev-charging-processed/training_data/validation_data.csv\n"
     ]
    }
   ],
   "source": [
    "process_data(input_data_path, training_data_folder = \"training_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://ev-charging-processed/training_data/training_data.csv\n",
      "s3://ev-charging-processed/training_data/validation_data.csv\n"
     ]
    }
   ],
   "source": [
    "training_data_folder = \"training_data\"\n",
    "training_data_object = \"training_data.csv\"\n",
    "validation_data_object = \"validation_data.csv\"\n",
    "\n",
    "# Load preprocessed data from S3\n",
    "training_data_path = f\"s3://{bucket_name}/{training_data_folder}/{training_data_object}\"\n",
    "validation_data_path = f\"s3://{bucket_name}/{training_data_folder}/{validation_data_object}\"\n",
    "\n",
    "print(training_data_path)\n",
    "print(validation_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set Up SageMaker Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_image = image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"1.7-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training and validation data inputs\n",
    "training_data = TrainingInput(\n",
    "    s3_data=training_data_path,\n",
    "    content_type=\"text/csv\"\n",
    ")\n",
    "\n",
    "# validation data\n",
    "validation_data = TrainingInput(\n",
    "    s3_data=validation_data_path,\n",
    "    content_type=\"text/csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base hyperparameters\n",
    "base_hyperparameters = {\"objective\": \"reg:absoluteerror\",\"num_round\":50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set S3 folder for model artifacts\n",
    "artifacts_folder = \"model-artifacts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create and Train XGBoost Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Estimator\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=xgboost_image,\n",
    "    hyperparameters=base_hyperparameters,\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    output_path=f's3://{bucket_name}/{artifacts_folder}',\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2024-10-17-14-14-29-386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-17 14:14:32 Starting - Starting the training job...\n",
      "2024-10-17 14:14:45 Starting - Preparing the instances for training...\n",
      "2024-10-17 14:15:22 Downloading - Downloading input data...\n",
      "2024-10-17 14:15:53 Downloading - Downloading the training image......\n",
      "2024-10-17 14:16:59 Training - Training image download completed. Training in progress...\u001b[34m[2024-10-17 14:17:09.488 ip-10-0-241-221.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-10-17 14:17:09.512 ip-10-0-241-221.ec2.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] Failed to parse hyperparameter objective value reg:absoluteerror to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] Determined 0 GPU(s) available on the instance.\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] File path /opt/ml/input/data/train of input files\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] Making smlinks from folder /opt/ml/input/data/train to folder /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] creating symlink between Path /opt/ml/input/data/train/training_data.csv and destination /tmp/sagemaker_xgboost_input_data/training_data.csv-747170516142876857\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] files path: /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] File path /opt/ml/input/data/validation of input files\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] Making smlinks from folder /opt/ml/input/data/validation to folder /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] creating symlink between Path /opt/ml/input/data/validation/validation_data.csv and destination /tmp/sagemaker_xgboost_input_data/validation_data.csv4989100202977398381\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] files path: /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] Train matrix has 904 rows and 31 columns\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] Validation matrix has 227 rows\u001b[0m\n",
      "\u001b[34m[2024-10-17 14:17:09.979 ip-10-0-241-221.ec2.internal:7 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-10-17 14:17:09.980 ip-10-0-241-221.ec2.internal:7 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-10-17 14:17:09.980 ip-10-0-241-221.ec2.internal:7 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-10-17 14:17:09.981 ip-10-0-241-221.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2024-10-17:14:17:09:INFO] Debug hook created from config\u001b[0m\n",
      "\u001b[34m[2024-10-17 14:17:10.042 ip-10-0-241-221.ec2.internal:7 INFO hook.py:427] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2024-10-17 14:17:10.045 ip-10-0-241-221.ec2.internal:7 INFO hook.py:491] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[0]#011train-mae:18.69364#011validation-mae:19.15488\u001b[0m\n",
      "\u001b[34m[1]#011train-mae:18.62066#011validation-mae:19.15052\u001b[0m\n",
      "\u001b[34m[2]#011train-mae:18.55599#011validation-mae:19.13923\u001b[0m\n",
      "\u001b[34m[3]#011train-mae:18.50182#011validation-mae:19.14048\u001b[0m\n",
      "\u001b[34m[4]#011train-mae:18.41847#011validation-mae:19.14688\u001b[0m\n",
      "\u001b[34m[5]#011train-mae:18.34940#011validation-mae:19.14905\u001b[0m\n",
      "\u001b[34m[6]#011train-mae:18.28435#011validation-mae:19.15580\u001b[0m\n",
      "\u001b[34m[7]#011train-mae:18.23891#011validation-mae:19.16133\u001b[0m\n",
      "\u001b[34m[8]#011train-mae:18.18166#011validation-mae:19.16640\u001b[0m\n",
      "\u001b[34m[9]#011train-mae:18.13502#011validation-mae:19.16304\u001b[0m\n",
      "\u001b[34m[10]#011train-mae:18.07602#011validation-mae:19.16416\u001b[0m\n",
      "\u001b[34m[11]#011train-mae:18.02669#011validation-mae:19.17078\u001b[0m\n",
      "\u001b[34m[12]#011train-mae:17.97595#011validation-mae:19.16546\u001b[0m\n",
      "\u001b[34m[13]#011train-mae:17.90579#011validation-mae:19.16495\u001b[0m\n",
      "\u001b[34m[14]#011train-mae:17.83760#011validation-mae:19.16441\u001b[0m\n",
      "\u001b[34m[15]#011train-mae:17.77777#011validation-mae:19.16606\u001b[0m\n",
      "\u001b[34m[16]#011train-mae:17.72239#011validation-mae:19.17159\u001b[0m\n",
      "\u001b[34m[17]#011train-mae:17.66288#011validation-mae:19.17229\u001b[0m\n",
      "\u001b[34m[18]#011train-mae:17.61649#011validation-mae:19.17012\u001b[0m\n",
      "\u001b[34m[19]#011train-mae:17.57673#011validation-mae:19.17529\u001b[0m\n",
      "\u001b[34m[20]#011train-mae:17.52853#011validation-mae:19.18507\u001b[0m\n",
      "\u001b[34m[21]#011train-mae:17.45734#011validation-mae:19.18078\u001b[0m\n",
      "\u001b[34m[22]#011train-mae:17.41529#011validation-mae:19.19524\u001b[0m\n",
      "\u001b[34m[23]#011train-mae:17.35448#011validation-mae:19.19934\u001b[0m\n",
      "\u001b[34m[24]#011train-mae:17.30807#011validation-mae:19.20075\u001b[0m\n",
      "\u001b[34m[25]#011train-mae:17.25590#011validation-mae:19.20129\u001b[0m\n",
      "\u001b[34m[26]#011train-mae:17.19580#011validation-mae:19.20636\u001b[0m\n",
      "\u001b[34m[27]#011train-mae:17.14299#011validation-mae:19.21765\u001b[0m\n",
      "\u001b[34m[28]#011train-mae:17.08146#011validation-mae:19.21370\u001b[0m\n",
      "\u001b[34m[29]#011train-mae:17.04079#011validation-mae:19.20900\u001b[0m\n",
      "\u001b[34m[30]#011train-mae:17.00165#011validation-mae:19.21287\u001b[0m\n",
      "\u001b[34m[31]#011train-mae:16.95887#011validation-mae:19.21555\u001b[0m\n",
      "\u001b[34m[32]#011train-mae:16.93297#011validation-mae:19.21496\u001b[0m\n",
      "\u001b[34m[33]#011train-mae:16.86786#011validation-mae:19.21071\u001b[0m\n",
      "\u001b[34m[34]#011train-mae:16.83585#011validation-mae:19.20856\u001b[0m\n",
      "\u001b[34m[35]#011train-mae:16.76751#011validation-mae:19.19774\u001b[0m\n",
      "\u001b[34m[36]#011train-mae:16.73420#011validation-mae:19.20020\u001b[0m\n",
      "\u001b[34m[37]#011train-mae:16.69623#011validation-mae:19.19392\u001b[0m\n",
      "\u001b[34m[38]#011train-mae:16.65206#011validation-mae:19.18962\u001b[0m\n",
      "\u001b[34m[39]#011train-mae:16.61022#011validation-mae:19.18944\u001b[0m\n",
      "\u001b[34m[40]#011train-mae:16.55948#011validation-mae:19.18549\u001b[0m\n",
      "\u001b[34m[41]#011train-mae:16.51302#011validation-mae:19.17410\u001b[0m\n",
      "\u001b[34m[42]#011train-mae:16.46317#011validation-mae:19.17093\u001b[0m\n",
      "\u001b[34m[43]#011train-mae:16.40760#011validation-mae:19.18208\u001b[0m\n",
      "\u001b[34m[44]#011train-mae:16.36725#011validation-mae:19.19246\u001b[0m\n",
      "\u001b[34m[45]#011train-mae:16.31246#011validation-mae:19.19905\u001b[0m\n",
      "\u001b[34m[46]#011train-mae:16.25975#011validation-mae:19.19186\u001b[0m\n",
      "\u001b[34m[47]#011train-mae:16.20010#011validation-mae:19.19706\u001b[0m\n",
      "\u001b[34m[48]#011train-mae:16.15024#011validation-mae:19.19946\u001b[0m\n",
      "\u001b[34m[49]#011train-mae:16.10680#011validation-mae:19.19476\u001b[0m\n",
      "\n",
      "2024-10-17 14:17:28 Uploading - Uploading generated training model\n",
      "2024-10-17 14:17:28 Completed - Training job completed\n",
      "Training seconds: 126\n",
      "Billable seconds: 126\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "estimator.fit({\"train\": training_data, \"validation\": validation_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:mae 16.106800079345703\n",
      "validation:mae 19.194759368896484\n"
     ]
    }
   ],
   "source": [
    "# Create a SageMaker client\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "# Get the training job description\n",
    "response = sagemaker_client.describe_training_job(TrainingJobName=\"sagemaker-xgboost-2024-10-17-14-14-29-386\")\n",
    "\n",
    "# Access the training job's CloudWatch metrics\n",
    "for metric in response[\"FinalMetricDataList\"]:\n",
    "    print(metric[\"MetricName\"], metric[\"Value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter ranges for tuning\n",
    "hyperparameter_ranges = {\n",
    "    \"max_depth\": IntegerParameter(3, 10),\n",
    "    \"eta\": ContinuousParameter(0.05, 0.7),\n",
    "    \"gamma\": ContinuousParameter(1, 5),\n",
    "    \"min_child_weight\": IntegerParameter(1, 10),\n",
    "    \"subsample\": ContinuousParameter(0.4, 1.0),\n",
    "    \"colsample_bytree\": ContinuousParameter(0.1, 1.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metric definitions and objective metric\n",
    "metric_definitions = [{\n",
    "    \"Name\": \"validation:mae\",\n",
    "    \"Regex\": \".*\\\\[validation-mae\\\\] ([0-9\\\\.]+)\"\n",
    "}]\n",
    "\n",
    "objective_metric_name = \"validation:mae\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the HyperparameterTuner\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=estimator,\n",
    "    objective_metric_name=objective_metric_name,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    metric_definitions=metric_definitions,\n",
    "    objective_type=\"Minimize\",\n",
    "    max_jobs=50,\n",
    "    max_parallel_jobs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating hyperparameter tuning job with name: xgb-tuning-job-4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "# Start the hyperparameter tuning job\n",
    "tuner.fit({\n",
    "    \"train\": training_data,\n",
    "    \"validation\": validation_data\n",
    "}, job_name=\"xgb-tuning-job-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Tuning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Training Job: {'TrainingJobName': 'xgb-tuning-job-4-047-bf5b00b3', 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:296062546796:training-job/xgb-tuning-job-4-047-bf5b00b3', 'CreationTime': datetime.datetime(2024, 10, 17, 16, 2, 53, tzinfo=tzlocal()), 'TrainingStartTime': datetime.datetime(2024, 10, 17, 16, 3, 1, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2024, 10, 17, 16, 3, 30, tzinfo=tzlocal()), 'TrainingJobStatus': 'Completed', 'TunedHyperParameters': {'colsample_bytree': '0.1', 'eta': '0.23737753183860888', 'gamma': '3.583377359657563', 'max_depth': '10', 'min_child_weight': '1', 'subsample': '1.0'}, 'FinalHyperParameterTuningJobObjectiveMetric': {'MetricName': 'validation:mae', 'Value': 19.0451602935791}, 'ObjectiveStatus': 'Succeeded'}\n"
     ]
    }
   ],
   "source": [
    "tuning_job_name = \"xgb-tuning-job-4\"\n",
    "response = sagemaker_client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuning_job_name)\n",
    "\n",
    "# Get the best training job\n",
    "best_training_job = response[\"BestTrainingJob\"]\n",
    "print(\"Best Training Job:\", best_training_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print details of the best training job\n",
    "best_training_job_name = best_training_job[\"TrainingJobName\"]\n",
    "best_training_job_response = sagemaker_client.describe_training_job(TrainingJobName=best_training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'_tuning_objective_metric': 'validation:mae', 'colsample_bytree': '0.1', 'eta': '0.23737753183860888', 'gamma': '3.583377359657563', 'max_depth': '10', 'min_child_weight': '1', 'num_round': '50', 'objective': 'reg:absoluteerror', 'subsample': '1.0'}\n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hyperparameters = best_training_job_response[\"HyperParameters\"]\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric Name: train:mae, Value: 17.688709259033203\n",
      "Metric Name: validation:mae, Value: 19.0451602935791\n",
      "Metric Name: validation:mae, Value: 19.0451602935791\n",
      "Metric Name: ObjectiveMetric, Value: 19.0451602935791\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "metrics = best_training_job_response.get(\"FinalMetricDataList\", [])\n",
    "for metric in metrics:\n",
    "    print(f\"Metric Name: {metric['MetricName']}, Value: {metric['Value']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Deploy the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-10-17 16:03:46 Starting - Found matching resource for reuse\n",
      "2024-10-17 16:03:46 Downloading - Downloading the training image\n",
      "2024-10-17 16:03:46 Training - Training image download completed. Training in progress.\n",
      "2024-10-17 16:03:46 Uploading - Uploading generated training model\n",
      "2024-10-17 16:03:46 Completed - Resource reused by training job: xgb-tuning-job-4-050-318522bb\n"
     ]
    }
   ],
   "source": [
    "# Create a SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "# Create an estimator from the best training job\n",
    "best_model = sagemaker.estimator.Estimator.attach(best_training_job_name, sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: xgb-tuning-job-4-047-bf5b00b3-2024-10-17-17-03-19-414\n",
      "INFO:sagemaker:Creating endpoint-config with name ev-charging-predictor-1\n",
      "INFO:sagemaker:Creating endpoint with name ev-charging-predictor-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "# Deploy the model\n",
    "predictor = best_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t2.medium\",  \n",
    "    endpoint_name=\"ev-charging-predictor-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model deployed. Endpoint name: ev-charging-predictor-1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model deployed. Endpoint name: {predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint ev-charging-predictor-1 has been scheduled for deletion\n"
     ]
    }
   ],
   "source": [
    "# delete the endpoint\n",
    "sagemaker_client.delete_endpoint(EndpointName=predictor.endpoint_name)\n",
    "print(f\"Endpoint {predictor.endpoint_name} has been scheduled for deletion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
